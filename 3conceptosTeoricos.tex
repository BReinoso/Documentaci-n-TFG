En este apartado se profundizará en los conceptos teóricos con los que se ha trabajado a lo largo de todo el proyecto.
\section{Conceptos teóricos en el lado del Servidor}
En este apartado se pretende explicar todos  los conceptos teóricos que se utilizan en el lado del servidor, tanto directamente usados por el alumno como los que se usan en proyectos o librerías de apoyo que se usan en el proyecto.
\subsection{Machine Learning}
El \textit{Machine Learing} o también conocido como aprendizaje computacional, entre otros nombres, es una rama de la inteligencia artificial que pretende conseguir el objetivo de que los computadores puedan aprender de manera automática. De forma más general se podría decir que en el \textit{machine learning} se pretende crear programas informáticos capaces de generalizar comportamientos a partir de una información no estructurara que suele estar suministrada en forma de ejemplos.

\paragraph{}El \textit{machine learning} tiene muchísimas aplicaciones y es ahora mismo un campo de la inteligencia artificial que se encuentra en estudio y del que se suceden bastantes proyectos.

\subsubsection{Tipos de algoritmos}
Podemos dividir los algoritmos en tres tipos, aunque puede haber más pero los más importantes o con los que se puede clasificar a todos los algoritmos o programas que nos encontremos:
\figura{0.5}{imgs/classi.png}{Ejemplo de clasificación.}{clasificacion}{}
\figura{0.5}{imgs/regre.png}{Ejemplo de regresión lineal.}{regresion}{}
\begin{itemize}
	\item \textbf{Aprendizaje Supervisado:} Este tipo de algoritmos crea una función que relaciona las entradas al sistema con las salidas del mismo.
	Aquí tendremos dos tipos de problemas a resolver, los cuáles son:	
	\begin{itemize}
		\item Clasificación: El problema de clasificación se trata de que a través de un conjunto de datos, entrenamos nuestro modelo para que este devuelva como resultado una clase que clasifique al valor de entrada. Internamente estamos creando una función que nos devolverá la clase perteneciente a cada ejemplo con el menor error posible. Ver \ref{clasificacion} \footnote{\url{https://en.wikipedia.org/?title=Machine_learning}}\cite{wiki:ML}.
		
		Ejemplo: Tenemos un conjunto de datos con una estructura del tipo (altitud, presión{ALTA, BAJA}). El modelo será entrenado para recibir un valor cualquiera de altitud, y este devolverá o bien, clase0 = Presión baja o, clase1= Presión alta. Lo que el modelo está preparado para devolver es una clase.
		\item Regresión: Este problema es bastante similar al de clasificación, pudiendo llegar a considerarse al de clasificación como un tipo de regresión. La principal diferencia de este con el de clasificación es que no esperamos una clase, sino un valor devuelto por la función construida, donde dicho valor será la predicción correspondiente al ejemplo. Internamente también creamos una función, pero esta está diseñada para devolver un valor numérico intentando predecir el estado del ejemplo, en función de los parámetros de entrada. Osea, la regresión nos devolverá un número como resultado, mientras que la clasificación devolverá una variable categórica.Ver imagen \ref{regresion}\footnote{\url{https://es.wikipedia.org/wiki/Regresión_lineal}}.
		
		Ejemplo: Tenemos un conjunto de datos del tipo (Altitud,Presión), en este caso tanto la altitud como la presión toman valores numéricos reales. El modelo se preparará para buscar una función que se ajuste mejor a los datos de entrenamiento. Ante un ejemplo para predecir, el modelo devolverá un número real, que será el valor esperado de la presión a esa altitud y no una clase.
	\end{itemize}
	\item \textbf{Aprendizaje no Supervisado:} En estos tipos de algoritmo se lleva a cabo el modelado con una serie ejemplos que tan sólo constan con sus valores de entrada, mientras que el sistema desconoce a qué clase o qué salida debiera surgir por cada ejemplo. Esto obliga al algoritmo a tener la capacidad de reconocimiento de patrones y ser capaz de diferenciar entre los ejemplos y dividirlos en grupos, en el que la salida será el grupo al que pertenece cada ejemplo.
	\item \textbf{Aprendizaje semisupervisado:} Este tipo de algoritmos son una combinación de los dos anteriores, tiene en cuenta tanto los ejemplos etiquetados como los no etiquetados.
\end{itemize}

Dentro de este tipo de algoritmos, que son los que serán usados en el proyecto; podemos identificar los más significativos y relacionados con el proyecto:
\begin{itemize}
	\item Máquinas de vectores de soporte: Se trata de un conjunto de algoritmos de aprendizaje supervisad, que son capaces de predecir la clase de un ejemplo nuevo que entre en el modelo. Aunque este tipo de algoritmos pueden ser usados tanto para regresión como para clasificación.
	
	En lo que se basan estos algoritmos es en que una máquina de vectores de soporte constituye un hiperplano, el cuál posee una dimensión muy elevada. Dentro de ese hiperplano se producen divisiones resultantes del entrenamiento del modelo, las cuáles cuanto mejor dividan el espacio, mejor será la clasificación\footnote{\url{https://es.wikipedia.org/wiki/Máquinas_de_vectores_de_soporte}}.
	\item Árboles: Los árboles de decisión son unos de los primeros métodos del \textit{machine learning}. Estos árboles están compuestos por una serie de nodos internos de decisión y unos nodos hojas, que se corresponden con la predicción o el resultado del modelo.\footnote{\url{https://regularizer.wordpress.com/2014/11/18/deep-learning-with-decision-trees/}}.
	\item Redes neuronales: Es un conjunto de algoritmos de aprendizaje tanto supervisado como no supervisado, los cuales usan el concepto biológico de la neurona y de las interconexiones neuronales para crear un modelo de neurona artificial y las redes neuronales. La neurona artificial tendrá una serie de entradas, que son procesadas por la función de activación de la neurona y devuelve una salida que será el parte o el resultado del modelo o bien podría ser la entrada a otra neurona, formando con ello grandes redes den neuronas artificiales.
\end{itemize}
\subsection{Deep Learning}
Se trata de un conjunto de algoritmos cuyo objetivo es intentar modelar abstracciones de alto nivel sobre los datos, usando para ello arquitecturas compuestas. Estas arquitecturas son de transformaciones no lineales y múltiples.

La definición de aprendizaje profundo o \textit{machine learning} no está muy clara, ya que existe más de una definición. Por norma general, hace referencia a algoritmos centrados en el aprendizaje de manera automática. Aún teniendo este punto en común, podemos encontrar diferentes algoritmos cuyas características los puede clasificar de la siguiente manera:
\begin{itemize}
	\item Usar un conjunto de capas en forma de cascada, o puestas de manera consecutiva una tras de otra, lo que significa que la salida de una capa será la entrada de la capa posterior. Los algoritmos de este tipo se enmarcan dentro del aprendizaje supervisado como en el no supervisado, esto implica la necesidad de que algunos algoritmos tengan la capacidad de detectar patrones.
	\item estar basados en el aprendizaje (no supervisado) de múltiples niveles de características o representaciones de datos. Las características de más alto nivel se derivan de las características de nivel inferior para formar una representación jerárquica \cite{wiki:AP}.
	\item aprender múltiples niveles de representación que corresponden con diferentes niveles de abstracción. Estos niveles forman una jerarquía de conceptos \cite{wiki:AP}.
\end{itemize}

Los algoritmos de aprendizaje profundo contrastan con los algoritmos de aprendizaje poco profundo por el número de transformaciones aplicadas a la señal mientras se propaga desde la capa de entrada a la capa de salida. Cada una de estas transformaciones incluye parámetros que se pueden entrenar como pesos y umbrales. No existe un estándar de facto para el número de transformaciones (o capas) que convierte a un algoritmo en profundo, pero la mayoría de investigadores en el campo considera que aprendizaje profundo implica más de dos transformaciones intermedias.
\subsection{Servicio Web}
\label{ConTeoServicioWeb}
Se trata de una tecnología que nos permite el correcto intercambio de datos entre distintas aplicaciones, para esto usa una serie de protocolos y estándares. El objetivo principal al usar este tipo de tecnología es conseguir que aplicaciones que trabajan en con distintos software, distinto idioma de programación, distinta localización e incluso con distinta plataforma de instalación; puedan comunicarse de manera adecuada y correcta consiguiendo que el paso de datos de una a otra sea posible no sólo de manera adecuada sino, también, correcta. Para conseguir este objetivo, los servicios web utilizan estándares abiertos, osea, que es accesible para todos.\footnote{\url{https://es.wikipedia.org/wiki/Servicio_web}}\cite{wiki:ServW}

Entre estos estándares los más relevantes con el proyecto y su desarrollo han sido:
\begin{itemize}
	\item XML: El formato de este tipo de documentos lo ha llevado a ser muy usado, incluso llega a ser la base para la definición de otros estándares.
	\item SOAP: Protocolos para establecer el intercambio de datos entre distintas aplicaciones. Hace referencia al tipo de dato.
	\item WSDL: Lenguaje para los servicios web con el que establecemos la comunicación con estos, en el se especifican los datos del servidor y los servicios que este ofrece, determinando los tipos de datos de respuesta y petición, los cuáles están establecidos en la especificación SOAP. Este  lenguaje esta basado en XML.
	\item REST: Protocolo que usa Http para establecer la conexión con el servidor y que, gracias a los distintos tipos de peticiones que posee, puede realizar las distintas operaciones en función de lo servicios que aporte el servicio web.
\end{itemize}
\section{Conceptos teóricos en el lado del Cliente}
\subsection{Funcionamiento de las librerías Text2Speech}
\label{ConTeoTTS}
Se tiene la intención de usar una librería para que el dispositivo lea las frases deseadas en voz alta, para esto se usa una librería del tipo \textit{text to speech}. Este tipo de librerías lo que hace es procesar los datos que se quieren leer y convertirlo en un clip de audio, en el que podemos escuchar una voz que lee lo deseado.
\figura{1}{imgs/TTS.png}{Gráfico de librería \textit{Text to Speech\cite{addison2005text}}}{TTS}{}

Para entender el funcionamiento de este tipo de librerías se ayuda de un pequeño gráfico (\ref{TTS})\footnote{\url{https://www.google.com/patents/US6865533}}, además se procede a poner una serie de pasos a través de los cuáles tienen que pasar los datos para llegar al clip final:
\begin{itemize}
	\item En primer lugar se almacena el texto en la memoria del dispositivo en el que se va a procesar con esta librería.
	\item Se procede a aplicar una serie de reglas de análisis léxico para convertir el texto en un conjunto de componentes de pluralidad.
	\item Se asocia la información de pronunciado y de significado a esta serie de componentes.
	
	\item El analizador fonético enmarca el texto usando las reglas de análisis fonético.
	\item Guardamos el conjunto de sonidos en memoria, cada sonido guardado es asociado con alguna información de pronunciación.
	\item Se recogen los sonidos asociados a los componentes para generar una fila o conjunto de sonidos que se asocian con el analizador fonético y con las reglas de análisis expresivo para generar la salida final.
\end{itemize}
\section{Conceptos teóricos asociados a los artículos de investigación}
\label{ConTeoCNN}
En apartados posteriores en la documentación (ver \ref{chap:EstadoArte}) se explicará de manera más o menos detallada los artículos de investigación asociados a las herramientas que se han utilizado, dentro de estos artículos tenemos conceptos teóricos algo avanzados, que se considera oportuno explicar en esta apartado para el posterior entendimiento de dichos artículos.
\subsection{Convolutional Neural Networks o Redes Neuronales Convolucionales}
En este apartado de los conceptos teóricos se procederá a explicar las Redes Neuronales Convolucionales\footnote{\url{http://cs231n.github.io/convolutional-networks/}}, las cuáles son muy importantes debido a que en el tratamiento de imágenes es una herramienta básica para el procesado de las mismas.

Las Redes Neuronales Convolucionales, CNNs a partir de ahora, son muy similares a las Redes Neuronales Multicapa. Poseen varias capas conectadas totalmente entre si, están formadas por un conjunto de neuronas artificiales, poseen pesos y bias que cambian en el entrenamiento de la red. Cada neurona recibe algunas entradas y obtiene el producto escalar de estas. La red entera posee una función objetivo. También posee una función de pérdida y se aplican todos los pasos normales que posee una Red Neuronal Multicapa común.

Parece que las CNNs no tienen nada nuevo en principio, pero la diferencia está en que la CNN lo que hace es dar por hecho que el input de la red es una imagen. Dar por hecho que la entrada de la red es una imagen nos aporta grandes beneficios, puesto que podemos configurar el resto de la red para tratar exclusivamente con este tipo de dato.
\subsubsection{Visión Global de la arquitectura de las CNNs}
Las CNNs toma ventaja de que el dato de entrada son imágenes y no otra cosa, lo que hace que la arquitectura de este tipo de redes sean restringidas de una manera más sensata. En particular, a diferencia de una red neuronal normal, las CNNs tienes sus neuronas organizadas en capas que conforman tres dimensiones:Altura, Anchura y Profundidad (la profundidad hace referencia al número de canales que tiene la imagen de entrada, pudiendo ser inclusive uno). 
\subsubsection{Ejemplo de una CNN}
Cada capa de una CNNN transforma un volumen de activaciones (la entrada de la capa, que pasa a través de las neuronas y su función de activación) es transformado en otro volumen con el uso de una función diferencial. Las CNNs tienen tres tipos principales de capas: \textbf{Capa Convolucional, Capa de puesta en común o  de \textit{Pooling} y Capa Completamente Conectada}. Si juntamos estas tras capas, entonces formamos una CNN completa.

Vamos a ver un pequeño ejemplo, aunque se detallará la explicación de las capas más adelante. Este ejemplo será para la clasificación de una y imagen y tiene una arquitectura [INPUT-CONV-RELU-POOL-FC] y unas 10 clases. La explicación de las capas será:
\begin{itemize}
	\item \textbf{INPUT[32X32X3]:} Esta capa es la de entrada y contendrá los píxeles de la imagen que se vaya a procesar, la imagen tendrá una resolución de 32 de altura por 32 de anchura; además podemos ver que tendrá 3 canales, que podrían ser RGB.
	\item \textbf{CONV:} Esta capa computará las salidas de cada neurona que están conectadas a regiones locales de la entrada, cada computación realiza un producto escalar entre los pesos y la región a la que están conectadas en el volumen de entrada. El resultado dará una matriz de tamaño [32X32X12].
	\item \textbf{RELU:} Esta capa aplicará una función de activación, que podría ser como la función max(0,x) con umbral cero. Esta capa no afectará al tamaño de la matriz resultante.
	\item \textbf{POOL:} Esta capa hará un cómputo que reducirá la resolución de la matriz, lo que deja la matriz con tamaño [16X16X12].
	\item \textbf{FC:} (\textit{fully-connected} o completamente conectada) Esta capa los resultados de clases, lo que provoca una matriz de tamaño [1X1X10], donde cada uno de los 10 números se corresponde con el resultado para cada clase.
\end{itemize}
\figura{1}{imgs/convnet.jpeg}{Gráfico de una CNN \cite{cs231nConv}}{CNN}{}

Por lo tanto, la CNN transforma la imagen original en una matriz de resultados para cada clase, que contiene la probabilidad de que la imagen de entrada pertenezca a esa clase. Para verlo de manera gráfica podemos ver la imagen \ref{CNN}.

\subsection{Recurrent Neural Networks o Redes Neuronales Recurrentes}
En el siguiente apartado se procede a explicar las Redes Neuronales Recurrentes \footnote{\url{http://karpathy.github.io/2015/05/21/rnn-effectiveness/}}\cite{cs231nRec}, RNN a partir de ahora. Esta clase de redes se usan en varios de los artículos que se procederá a explicar en el apartado de Estado del Arte (\ref{chap:EstadoArte}).

Las RNNs se consideran un caso especial de redes neuronales también, esto se debe a que en general las redes neuronales tienen un conexión entre las capas de tal manera que la comunicación entre capas se hace sólo hacia delante. Por otro lado, las RNNs permiten conexiones recurrentes entre las distintas capas, esto significa que la información ya no viaja sólo en dirección hacia delante sino que existe una propagación de esta información hacia atrás (\textit{back-propagation}). El hecho de permitir que exista este tipo de conexiones entre las distintas capas de la red neuronal añade un elemento temporal a la red, entonces esta puede predecir eventos adelante en el tiempo.

Cuando hablamos de una RNN, entonces estamos hablando de un tipo de red cuyo dato de entrada será siempre un vector, osea una secuencia de datos. La salida de esta red es también un vector de datos. En principio pudiera llegar a parecer extraño que tanto los datos de entrada como los de salida sean tratados como vectores o secuencias de datos, pero esto nos permite que la red procese los datos de una manera secuencial.

\subsubsection{Visión global de la arquitectura de las RNNs}
\label{ConTeoRNN}
La arquitectura de las RNNs no tiene diferencia, en cuanto a capas se refiere, con las redes neuronales normales. La redes recurrentes poseen las mismas características que estas, estas tienen una función de activación dentro de la neurona, tienen capa de entrada, capas ocultas y capa de salida, poseen una serie de pesos que van cambiando en función del entrenamiento de la red.

\figura{0.7}{imgs/NeuronCon.png}{Gráfico de conexiones recurrentes en una RNN}{RNNCon}{}
La diferencia de una RNN respecto de una red neuronal común o básica se encuentra en el modo en el que están conectadas las neuronas con respecto al resto de neuronas. En las redes básicas las neuronas están conectadas solamente con las capas posteriores, lo que significa que la propagación de la información se hace únicamente hacia a delante sin que exista ningún tipo de retroalimentación. En cambio, las neuronas de una RNN posee también conexiones recurrentes, las conexiones recurrentes pueden ser de tres tipos, se puede ver de forma gráfica en la imagen \ref{RNNCon}:
\begin{itemize}
	\item \textbf{1.-} Una conexión de una neurona de una capa A con otra neurona de la misma capa A
	\item \textbf{2.-} Una conexión de una neurona de una capa A con otra neurona de otra capa B, pero que se encuentra en un instante  de tiempo anterior a esta, osea, se produce una propagación hacia atrás de los datos.
	\item \textbf{3.-} Una conexión de una neurona de cualquier capa con ella misma, una conexión a ella misma.
\end{itemize}

El hecho de añadir todos estas posibles conexiones también provoca que se añadan más pesos para formalizar la red y se necesite el uso de más memoria, además de que los pesos de las capas en una conexión recurrente son guardados en un estado intermedio al cuál acceden las neuronas objetivo de la conexión recurrente para producir predicciones temporales.