En este capítulo se profundizará en los conceptos teóricos con los que se ha trabajado a lo largo de todo el proyecto.
\section{Conceptos teóricos en el lado del Servidor}
En este apartado se pretende explicar todos  los conceptos teóricos que se utilizan en el lado del servidor, tanto directamente usados por el alumno, como los que se usan en proyectos o librerías de apoyo que se usan en el proyecto.
\subsection{Machine Learning}
El \textit{Machine Learning} o también conocido como aprendizaje computacional, entre otros nombres, es una rama de la Inteligencia Artificial que pretende conseguir el objetivo de que los computadores puedan aprender de manera automática. De forma más general, se podría decir que el \textit{Machine Learning} pretende crear programas informáticos capaces de generalizar comportamientos a partir de una información no estructurara que suele estar suministrada en forma de ejemplos.

El \textit{Machine Learning} tiene muchísimas aplicaciones y es ahora mismo un campo de la Inteligencia Artificial que se encuentra en activo y del que surgen bastantes proyectos.

\subsubsection{Tipos de algoritmos}
Aunque existen otras, la primera gran clasificación de los algoritmos de aprendizaje automático es en las tres siguientes categorías:
\figura{0.5}{imgs/classi.png}{Ejemplo de clasificación.}{clasificacion}{}
\figura{0.5}{imgs/regre.png}{Ejemplo de regresión lineal.}{regresion}{}
\begin{itemize}
	\item \textbf{Aprendizaje Supervisado:} Este tipo de algoritmos crea una función que relaciona las entradas al sistema con las salidas del mismo.
	Aquí tendremos dos tipos de problemas a resolver, los cuáles son:	
	\begin{itemize}
		\item Clasificación: El problema de clasificación se trata de que a través de un conjunto de datos, entrenamos nuestro modelo para que este devuelva como resultado una clase que clasifique al valor de entrada. Internamente estamos creando una función que nos devolverá la clase perteneciente a cada ejemplo con el menor error posible. En la Figura \ref{clasificacion} se puede ver un ejemplo de clasificación en el que se quiere distinguir dos clases y donde la frontera de decisión es lineal \cite{wiki:ML}.
		
		Ejemplo: Tenemos un conjunto de datos con una estructura del tipo (altitud, presión{ALTA, BAJA}). El modelo será entrenado para recibir un valor cualquiera de altitud, y este devolverá o bien, clase0 = Presión baja o, clase1= Presión alta. Lo que el modelo está preparado para devolver es una clase.
		\item Regresión: Este problema es bastante similar al de clasificación, pudiendo llegar a considerarse al de clasificación como un tipo de regresión. La principal diferencia de este con el de clasificación es que no esperamos una clase, sino un valor devuelto por la función construida, donde dicho valor será la predicción correspondiente al ejemplo. Internamente también creamos una función, pero esta está diseñada para devolver un valor numérico intentando predecir el estado del ejemplo, en función de los parámetros de entrada. Osea, la regresión nos devolverá un número como resultado, mientras que la clasificación devolverá una variable categórica. En la figura \ref{regresion} podemos ver un ejemplo de regresión lineal a partir de una serie de ejemplos \cite{wiki:RegLin}.
		
		Ejemplo: Tenemos un conjunto de datos del tipo (Altitud,Presión), en este caso tanto la altitud como la presión toman valores numéricos reales. El modelo se preparará para buscar una función que se ajuste mejor a los datos de entrenamiento. Ante un ejemplo para predecir, el modelo devolverá un número real, que será el valor esperado de la presión a esa altitud y no una clase.
	\end{itemize}
	\item \textbf{Aprendizaje no Supervisado:} En este tipo de algoritmo se lleva a cabo el modelado con una serie ejemplos que tan sólo constan de sus valores de entrada, mientras que el sistema desconoce a qué clase o qué salida le corresponde a cada ejemplo. Esto obliga al algoritmo a tener la capacidad de reconocimiento de patrones y ser capaz de diferenciar entre los ejemplos y dividirlos en grupos, en el que el resultado de la ejecución del algoritmo será el grupo al que pertenece cada ejemplo.
	\item \textbf{Aprendizaje semisupervisado:} Este tipo de algoritmos son una combinación de los dos anteriores, tiene en cuenta tanto los ejemplos etiquetados como los no etiquetados.
\end{itemize}

Dentro de este tipo de algoritmos, que son los que serán usados en el proyecto; podemos identificar los más significativos y relacionados con el proyecto:
\begin{itemize}
	\item Máquinas de vectores soporte: Se trata de un conjunto de algoritmos de aprendizaje supervisado, su principal particularidad es que a la hora de aprender la frontera de decisión, intenta encontrar aquella frontera que esté lo más alejada posible de ambas clases. Se dice que intentan maximizar el ``margen'', la distancia entre la frontera y las instancias más cercanas a la misma. Estas instancias más cercanas reciben el nombre de vectores soporte, de ahí  el nombre del método.
	
	 Aunque inicialmente están diseñados para resolver problemas de clasificación, se han publicado variantes capaces de resolver problemas de regresión.
	
	Aunque en el modelo básico la frontera que se aprende es lineal, si se añaden nuevas características basadas en las existentes, lo que en la práctica incrementa la dimensión espacial del conjunto de datos, la frontera aprendida puede ser más compleja que la lineal. Por ejemplo, un conjunto de datos que consista en las coordenadas $x$,$y$, y donde una de las clases se encuentre en el origen y la otra en  un anillo en torno a la primera, no es linealmente separable (no hay una manera de trazar una línea recta que separe ambas clases, dejando cada una a un lado de la línea). Pero si se añade como característica el producto de las coordenadas $x$,$y$, se obtiene un nuevo conjunto de datos de tres dimensiones que sí es linealmente separable. Ahora una de las clases sigue siendo una nube en torno al origen, pero la otra clase se aleja de este, permitiendo que un plano separe a ambas. Para clarificar este ejemplo podemos ver la Figura \ref{maqSop} \cite{MaqSop}.
\figura{0.7}{imgs/rsi2.png}{Cambio de dimensionalidad en máquinas de vectores soporte.}{maqSop}{}
	\item Árboles: Los árboles de decisión son unos de los primeros métodos del \textit{machine learning}. Estos árboles están compuestos por una serie de nodos internos de decisión y unos nodos hojas, que se corresponden con la predicción o el resultado del modelo \cite{ArbDec}. Cuando el árbol está construido, su uso es simple. Una nueva instanciaa se deriva al subárbol izquierdo o derecho del nodo raíz dependiendo de cuál sea el valor de uno de sus atributos. Ahora se considera el nodo raíz del nuevo árbol y se evalúaa una nueva decisión que que se basará en otro atributo, o en el mismo, aunque considerando un valor de división distinto. Así sucesivamente hasta llegar a un nodo hoja, momento en el que se predecirá la clase de la instancia de acuerdo a la etiqueta asignada al nodo hoja. Esto puede verse más claro en la Figura \ref{arbDec}.
\figura{0.7}{imgs/arb.png}{Clasificación con árbol de decisión \cite{ArbDecIm}.}{arbDec}{}
	El proceso de aprendizaje consiste en determinar los atributos y valores de división de cada nodo.
	\item Redes neuronales: Es un conjunto de algoritmos de aprendizaje tanto supervisado como no supervisado, los cuales usan el concepto biológico de la neurona y de las interconexiones neuronales para crear un modelo de neurona artificial y las redes neuronales. La neurona artificial tendrá una serie de entradas, que son procesadas por la función de activación de la neurona y devuelve una salida que será parte o el resultado del modelo, o bien podría ser la entrada a otra neurona, formando con ello grandes redes de neuronas artificiales. Las entradas a las neuronas procedentes de otras tienen un peso que indica cuánto influye esa entrada en el valor que genera la neurona. El proceso de aprendizaje consiste en determinar estos pesos.
\end{itemize}
\subsection{Deep Learning}
Se trata de un conjunto de algoritmos cuyo objetivo es intentar modelar abstracciones de alto nivel sobre los datos, usando para ello arquitecturas compuestas. Estas arquitecturas son de transformaciones no lineales y múltiples.

La definición de aprendizaje profundo o \textit{Machine Learning} no está muy clara, ya que existe más de una definición. Por norma general, hace referencia a algoritmos centrados en el aprendizaje de manera automática. Aún teniendo este punto en común, podemos encontrar diferentes algoritmos cuyas características son las siguientes:
\begin{itemize}
	\item Usar un conjunto de capas en forma de cascada, o puestas de manera consecutiva una tras de otra, lo que significa que la salida de una capa será la entrada de la capa posterior. Los algoritmos de este tipo pueden ser tanto de aprendizaje supervisado como de no supervisado, esto implica la necesidad de que algunos algoritmos tengan la capacidad de detectar patrones.
	\item Deben estar basados en el aprendizaje no supervisado de varios niveles de características o representaciones de datos. Las características forman una representación jerárquica, en las que las características de bajo nivel derivan a las de alto nivel.
	\item Aprender en varios niveles de abstracción que se corresponden a distintos niveles de representación, que forman una jerarquía de conceptos \cite{wiki:AP}.
\end{itemize}

Los algoritmos de aprendizaje profundo contrastan con los algoritmos de aprendizaje poco profundo por el número de transformaciones aplicadas a la entrada mientras se propaga desde la capa de entrada a la capa de salida. Cada una de estas transformaciones incluye parámetros que se pueden entrenar como pesos y umbrales. No existe un estándar de facto para el número de transformaciones (o capas) que convierte a un algoritmo en profundo, pero la mayoría de investigadores en el campo considera que aprendizaje profundo implica más de dos transformaciones intermedias.
\subsection{Servicio Web}
\label{ConTeoServicioWeb}
Se trata de una tecnología que nos permite el correcto intercambio de datos entre distintas aplicaciones, para esto usa una serie de protocolos y estándares. El objetivo principal al usar este tipo de tecnología es conseguir que aplicaciones que trabajan en con distintos software, distinto idioma de programación, distinta localización e incluso con distinta plataforma de instalación; puedan comunicarse de manera adecuada y correcta consiguiendo que el paso de datos de una a otra sea posible, no sólo de manera adecuada sino, también, correcta. Para conseguir este objetivo, los servicios web utilizan estándares abiertos, osea, que es accesible para todos \cite{wiki:ServW}.

Entre estos estándares los más relevantes en este proyecto y su desarrollo han sido:
\begin{itemize}
	\item XML: El formato de este tipo de documentos lo ha llevado a ser muy usado, incluso llega a ser la base para la definición de otros estándares. Este estándar se uso en la primera parte del proyecto, para una explicación más detallada ver el Capítulo \ref{chap:AspectosRelevantes}.
	\item SOAP: Protocolos para establecer el intercambio de datos entre distintas aplicaciones. Hace referencia al tipo de dato. Estos protocolos se uso en la primera parte del proyecto, para una explicación más detallada ver el Capítulo \ref{chap:AspectosRelevantes}.
	\item WSDL: Lenguaje para los servicios web con el que establecemos la comunicación con estos, en el se especifican los datos del servidor y los servicios que este ofrece, determinando los tipos de datos de respuesta y petición, los cuáles están establecidos en la especificación SOAP. Este  lenguaje esta basado en XML. Este lenguaje se uso en la primera parte del proyecto, para una explicación más detallada ver el Capítulo \ref{chap:AspectosRelevantes}.
	\item REST: Protocolo que usa Http para establecer la conexión con el servidor y que, gracias a los distintos tipos de peticiones que posee, puede realizar las distintas operaciones en función de lo servicios que aporte el servicio web.
\end{itemize}
\section{Conceptos teóricos en el lado del Cliente}
\subsection{Funcionamiento de las librerías Text2Speech}
\label{ConTeoTTS}
Se usó una biblioteca para que el dispositivo lea las frases deseadas en voz alta, para esto se usa una librería del tipo \textit{text to speech}. Este tipo de bibliotecas lo que hace es procesar los datos que se quieren leer y convertirlos en un clip de audio, en el que podemos escuchar una voz que lee lo deseado.
\figura{1}{imgs/TTS.png}{Gráfico de librería \textit{Text to Speech\cite{addison2005text}}}{TTS}{}

Para entender el funcionamiento de este tipo de bibliotecas nos vamos a ayudar del gráfico que se muestra en la Figura \ref{TTS}, además se procede a poner una serie de pasos a través de los cuáles tienen que pasar los datos para llegar al clip final:
\begin{itemize}
	\item En primer lugar se almacena el texto en la memoria del dispositivo en el que se va a procesar con esta biblioteca.
	\item Se procede a aplicar una serie de reglas de análisis léxico para convertir el texto en un conjunto de componentes de pluralidad.
	\item Se asocia la información de pronunciado y de significado a esta serie de componentes.
	
	\item El analizador fonético enmarca el texto usando las reglas de análisis fonético.
	\item Guardamos el conjunto de sonidos en memoria, cada sonido guardado es asociado con alguna información de pronunciación.
	\item Se recogen los sonidos asociados a los componentes para generar una fila o conjunto de sonidos que se asocian con el analizador fonético y con las reglas de análisis expresivo para generar la salida final.
\end{itemize}
\section{Conceptos teóricos asociados a los artículos de investigación}
\label{ConTeoCNN}
En apartados posteriores en la documentación (ver Capítulo \ref{chap:EstadoArte}) se explicará de manera más o menos detallada los artículos de investigación asociados a las herramientas que se han utilizado, dentro de estos artículos tenemos conceptos teóricos algo avanzados, que se considera oportuno explicar en esta apartado para el posterior entendimiento de dichos artículos.
\subsection{Convolutional Neural Networks o Redes Neuronales Convolucionales}
En este apartado de los conceptos teóricos se procederá a explicar las Redes Neuronales Convolucionales\cite{cs231nConv}, las cuáles son muy importantes debido a que en el tratamiento de imágenes es una herramienta básica para el procesado de las mismas.

Las Redes Neuronales Convolucionales, CNNs a partir de ahora, son muy similares a las Redes Neuronales Multicapa. Poseen varias capas conectadas totalmente entre si, están formadas por un conjunto de neuronas artificiales, poseen pesos y umbrales que cambian en el entrenamiento de la red. Cada neurona recibe algunas entradas y obtiene el producto escalar de estas. La red entera posee una función objetivo. También posee una función de pérdida y se aplican todos los pasos normales que posee una Red Neuronal Multicapa común.

Parece que las CNNs no tienen nada nuevo en principio, pero la diferencia está en que la CNN lo que hace es dar por hecho que el input de la red es una imagen. Dar por hecho que la entrada de la red es una imagen nos aporta grandes beneficios, puesto que podemos configurar el resto de la red para tratar exclusivamente con este tipo de dato.
\subsubsection{Visión Global de la arquitectura de las CNNs}
Las CNNs toma ventaja de que el dato de entrada son imágenes y no otra cosa, lo que hace que la arquitectura de este tipo de redes sean restringidas de una manera más sensata. En particular, a diferencia de una red neuronal normal, las CNNs tienes sus neuronas organizadas en capas que conforman tres dimensiones: Altura, Anchura y Profundidad (la profundidad hace referencia al número de canales que tiene la imagen de entrada, pudiendo ser inclusive uno). 
\subsubsection{Ejemplo de una CNN}
En cada capa de una CNN un volumen de activaciones (la entrada de la capa, que pasa a través de las neuronas y su función de activación) es transformado en otro volumen con el uso de una función diferencial. Las CNNs tienen tres tipos principales de capas: \textbf{Capa Convolucional, Capa de puesta en común o  de \textit{Pooling} y Capa Completamente Conectada}. Si juntamos estas tres capas, entonces formamos una CNN completa.

Vamos a ver un pequeño ejemplo, aunque se detallará la explicación de las capas más adelante. Este ejemplo será para la clasificación de una imagen y tiene una arquitectura [INPUT-CONV-RELU-POOL-FC] y unas 10 clases. La explicación de las capas será:
\begin{itemize}
	\item \textbf{INPUT[32X32X3]:} Esta capa es la de entrada y contendrá los píxeles de la imagen que se vaya a procesar, la imagen tendrá una resolución de 32 de altura por 32 de anchura; además podemos ver que tendrá 3 canales, que podrían ser RGB.
	\item \textbf{CONV:} Esta capa computará las salidas de cada neurona que están conectadas a regiones locales de la entrada, cada computación realiza un producto escalar entre los pesos y la región a la que están conectadas en el volumen de entrada. El resultado dará una matriz de tamaño [32X32X12].
	\item \textbf{RELU:} Esta capa aplicará una función de activación, que podría ser como la función max(0,x) con umbral cero. Esta capa no afectará al tamaño de la matriz resultante.
	\item \textbf{POOL:} Esta capa hará un cómputo que reducirá la resolución de la matriz, lo que deja la matriz con tamaño [16X16X12].
	\item \textbf{FC:} (\textit{fully-connected} o completamente conectada) Esta capa los resultados de clases, lo que provoca una matriz de tamaño [1X1X10], donde cada uno de los 10 números se corresponde con el resultado para cada clase.
\end{itemize}
\figura{1}{imgs/convnet.jpeg}{Gráfico de una CNN \cite{cs231nConv}}{CNN}{}

Por lo tanto, la CNN transforma la imagen original en una matriz de resultados para cada clase, que contiene la probabilidad de que la imagen de entrada pertenezca a esa clase. Para verlo de manera gráfica podemos ver la Figura \ref{CNN}.

\subsection{Recurrent Neural Networks o Redes Neuronales Recurrentes}
En el siguiente apartado se procede a explicar las Redes Neuronales Recurrentes \cite{cs231nRec}, RNN a partir de ahora. Esta clase de redes se usan en varios de los artículos que se procederá a explicar en el apartado de Estado del Arte (\ref{chap:EstadoArte}).

Las RNNs se consideran un caso especial de redes neuronales también, esto se debe a que en general las redes neuronales tienen un conexión entre las capas de tal manera que la comunicación entre capas se hace sólo hacia delante. Por otro lado, las RNNs permiten conexiones recurrentes entre las distintas capas, esto significa que la información ya no viaja sólo en dirección hacia delante sino que existe una propagación de esta información hacia atrás (\textit{back-propagation}). El hecho de permitir que exista este tipo de conexiones entre las distintas capas de la red neuronal añade un elemento temporal a la red, entonces esta puede predecir eventos adelante en el tiempo.

Cuando hablamos de una RNN, entonces estamos hablando de un tipo de red cuyo dato de entrada será siempre un vector, osea una secuencia de datos. La salida de esta red es también un vector de datos. En principio pudiera llegar a parecer extraño que tanto los datos de entrada como los de salida sean tratados como vectores o secuencias de datos, pero esto nos permite que la red procese los datos de una manera secuencial.

\subsubsection{Visión global de la arquitectura de las RNNs}
\label{ConTeoRNN}
La arquitectura de las RNNs no tiene diferencia, en cuanto a capas se refiere, con las redes neuronales normales. La redes recurrentes poseen las mismas características que estas, estas tienen una función de activación dentro de la neurona, tienen capa de entrada, capas ocultas y capa de salida, poseen una serie de pesos que van cambiando en función del entrenamiento de la red.

\figura{0.7}{imgs/NeuronCon.png}{Gráfico de conexiones recurrentes en una RNN}{RNNCon}{}
La diferencia de una RNN respecto de una red neuronal común o básica se encuentra en el modo en el que están conectadas las neuronas con respecto al resto de neuronas. En las redes básicas las neuronas están conectadas solamente con las capas posteriores, lo que significa que la propagación de la información se hace únicamente hacia a delante sin que exista ningún tipo de retroalimentación. En cambio, las neuronas de una RNN posee también conexiones recurrentes, las conexiones recurrentes pueden ser de tres tipos, se puede ver de forma gráfica en la imagen \ref{RNNCon}:
\begin{enumerate}
	\item Una conexión de una neurona de una capa A con otra neurona de la misma capa A
	\item  Una conexión de una neurona de una capa A con otra neurona de otra capa B, pero que se encuentra en un instante  de tiempo anterior a esta, osea, se produce una propagación hacia atrás de los datos.
	\item Una conexión de una neurona de cualquier capa con ella misma, una conexión a ella misma.
\end{enumerate}

El hecho de añadir todos estas posibles conexiones también provoca que se añadan más pesos para formalizar la red y se necesite el uso de más memoria, además de que los pesos de las capas en una conexión recurrente son guardados en un estado intermedio al cuál acceden las neuronas objetivo de la conexión recurrente para producir predicciones temporales.